=== "OpenAI"
    å®‰è£… langchain-openai åŒ…

    ```bash
    pip install langchain-openai
    ```

    ç¡®ä¿å·²å°† OpenAI å¯†é’¥å‡†å¤‡å¥½å¹¶è®¾ç½®åœ¨ç¯å¢ƒå˜é‡ä¸­

    ```python
    import os
    os.environ["OPENAI_API_KEY"] = "your-openai-key"
    ```

    ä½¿ç”¨ `LangchainLLMWrapper` åŒ…è£… LLMï¼Œä»¥ä¾¿åœ¨ ragas ä¸­ä½¿ç”¨ã€‚

    ```python
    from ragas.llms import LangchainLLMWrapper
    from langchain_openai import ChatOpenAI
    from ragas.embeddings import OpenAIEmbeddings
    import openai
    
    generator_llm = LangchainLLMWrapper(ChatOpenAI(model="gpt-4o"))
    openai_client = openai.OpenAI()
    generator_embeddings = OpenAIEmbeddings(client=openai_client)
    ```


=== "AWS"
    å®‰è£… langchain-aws åŒ…

    ```bash
    pip install langchain-aws
    ```

    ç„¶åéœ€è¦è®¾ç½® AWS å‡­æ®å’Œé…ç½®

    ```python
    config = {
        "credentials_profile_name": "your-profile-name",  # ä¾‹å¦‚ "default"
        "region_name": "your-region-name",  # ä¾‹å¦‚ "us-east-1"
        "llm": "your-llm-model-id",  # ä¾‹å¦‚ "anthropic.claude-3-5-sonnet-20241022-v2:0"
        "embeddings": "your-embedding-model-id",  # ä¾‹å¦‚ "amazon.titan-embed-text-v2:0"
        "temperature": 0.4,
    }
    ```

    å®šä¹‰ LLM å¹¶ä½¿ç”¨ `LangchainLLMWrapper` åŒ…è£…ï¼Œä»¥ä¾¿åœ¨ ragas ä¸­ä½¿ç”¨ã€‚

    ```python
    from langchain_aws import ChatBedrockConverse
    from langchain_aws import BedrockEmbeddings
    from ragas.llms import LangchainLLMWrapper
    from ragas.embeddings import LangchainEmbeddingsWrapper

    generator_llm = LangchainLLMWrapper(ChatBedrockConverse(
        credentials_profile_name=config["credentials_profile_name"],
        region_name=config["region_name"],
        base_url=f"https://bedrock-runtime.{config['region_name']}.amazonaws.com",
        model=config["llm"],
        temperature=config["temperature"],
    ))
    generator_embeddings = LangchainEmbeddingsWrapper(BedrockEmbeddings(
        credentials_profile_name=config["credentials_profile_name"],
        region_name=config["region_name"],
        model_id=config["embeddings"],
    ))
    ```

    å¦‚éœ€äº†è§£æ›´å¤šå…³äºä½¿ç”¨å…¶ä»– AWS æœåŠ¡çš„ä¿¡æ¯ï¼Œè¯·å‚é˜… [langchain-aws](https://python.langchain.com/docs/integrations/providers/aws/) æ–‡æ¡£ã€‚

=== "Google Cloud"
    Google æä¾›ä¸¤ç§è®¿é—®å…¶æ¨¡å‹çš„æ–¹å¼ï¼šGoogle AI å’Œ Google Cloud Vertex AIã€‚Google AI ä»…éœ€ Google è´¦å·å’Œ API å¯†é’¥ï¼Œè€Œ Vertex AI éœ€è¦å…·å¤‡ä¼ä¸šåŠŸèƒ½çš„ Google Cloud è´¦å·ã€‚

    é¦–å…ˆå®‰è£…æ‰€éœ€åŒ…ï¼š

    ```bash
    pip install langchain-google-genai langchain-google-vertexai
    ```

    ç„¶åæ ¹æ®æ‰€é€‰çš„ API è®¾ç½®å‡­æ®ï¼š

    Google AIï¼š

    ```python
    import os
    os.environ["GOOGLE_API_KEY"] = "your-google-ai-key"  # æ¥è‡ª https://ai.google.dev/
    ```

    Vertex AIï¼š

    ```python
    # ç¡®ä¿å·²é…ç½®å‡­æ®ï¼ˆgcloudã€å·¥ä½œè´Ÿè½½èº«ä»½ç­‰ï¼‰
    # æˆ–è®¾ç½®æœåŠ¡è´¦å· JSON è·¯å¾„ï¼š
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "path/to/service-account.json"
    ```

    å®šä¹‰é…ç½®ï¼š

    ```python
    config = {
        "model": "gemini-1.5-pro",  # æˆ–å…¶ä»–æ¨¡å‹ ID
        "temperature": 0.4,
        "max_tokens": None,
        "top_p": 0.8,
        # ä»… Vertex AIï¼š
        "project": "your-project-id",  # Vertex AI å¿…å¡«
        "location": "us-central1",     # Vertex AI å¿…å¡«
    }
    ```

    åˆå§‹åŒ– LLM å¹¶åŒ…è£…ä»¥ä¾› ragas ä½¿ç”¨ï¼š

    ```python
    from ragas.llms import LangchainLLMWrapper
    from ragas.embeddings import LangchainEmbeddingsWrapper

    # æ ¹æ®æ‰€ç”¨ API é€‰æ‹©å¯¹åº”å¯¼å…¥ï¼š
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_google_vertexai import ChatVertexAI

    # ä½¿ç”¨ Google AI Studio åˆå§‹åŒ–
    generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(
        model=config["model"],
        temperature=config["temperature"],
        max_tokens=config["max_tokens"],
        top_p=config["top_p"],
    ))

    # æˆ–ä½¿ç”¨ Vertex AI åˆå§‹åŒ–
    generator_llm = LangchainLLMWrapper(ChatVertexAI(
        model=config["model"],
        temperature=config["temperature"],
        max_tokens=config["max_tokens"],
        top_p=config["top_p"],
        project=config["project"],
        location=config["location"],
    ))
    ```


    å¯é€‰é…ç½®å®‰å…¨è®¾ç½®ï¼š

    ```python
    from langchain_google_genai import HarmCategory, HarmBlockThreshold

    safety_settings = {
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        # æŒ‰éœ€æ·»åŠ å…¶ä»–å®‰å…¨è®¾ç½®
    }

    # åœ¨ LLM åˆå§‹åŒ–æ—¶åº”ç”¨
    generator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(
        model=config["model"],
        temperature=config["temperature"],
        safety_settings=safety_settings,
    ))
    ```

    åˆå§‹åŒ–åµŒå…¥æ¨¡å‹å¹¶åŒ…è£…ä»¥ä¾› ragas ä½¿ç”¨ï¼š

    ```python
    # Google AI Studio åµŒå…¥
    from langchain_google_genai import GoogleGenerativeAIEmbeddings

    generator_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",  # Google æ–‡æœ¬åµŒå…¥æ¨¡å‹
        task_type="retrieval_document"  # å¯é€‰ï¼šæŒ‡å®šä»»åŠ¡ç±»å‹
    ))
    ```

    ```python
    # Vertex AI åµŒå…¥
    from langchain_google_vertexai import VertexAIEmbeddings

    generator_embeddings = LangchainEmbeddingsWrapper(VertexAIEmbeddings(
        model_name="textembedding-gecko@001",  # æˆ–å…¶ä»–å¯ç”¨æ¨¡å‹
        project=config["project"],  # ä½ çš„ GCP é¡¹ç›® ID
        location=config["location"]  # ä½ çš„ GCP åŒºåŸŸ
    ))
    ```

    æœ‰å…³å¯ç”¨æ¨¡å‹ã€åŠŸèƒ½å’Œé…ç½®çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…ï¼š[Google AI æ–‡æ¡£](https://ai.google.dev/docs)ã€[Vertex AI æ–‡æ¡£](https://cloud.google.com/vertex-ai/docs)ã€[LangChain Google AI é›†æˆ](https://python.langchain.com/docs/integrations/chat/google_generative_ai)ã€[LangChain Vertex AI é›†æˆ](https://python.langchain.com/docs/integrations/chat/google_vertex_ai)


=== "Azure"
    å®‰è£… langchain-openai åŒ…

    ```bash
    pip install langchain-openai
    ```

    ç¡®ä¿å·²å°† Azure OpenAI å¯†é’¥å‡†å¤‡å¥½å¹¶è®¾ç½®åœ¨ç¯å¢ƒå˜é‡ä¸­ã€‚

    ```python
    import os
    os.environ["AZURE_OPENAI_API_KEY"] = "your-azure-openai-key"

    # å…¶ä»–é…ç½®
    azure_config = {
        "base_url": "",  # ä½ çš„ç«¯ç‚¹
        "model_deployment": "",  # ä½ çš„æ¨¡å‹éƒ¨ç½²åç§°
        "model_name": "",  # ä½ çš„æ¨¡å‹åç§°
        "embedding_deployment": "",  # ä½ çš„åµŒå…¥éƒ¨ç½²åç§°
        "embedding_name": "",  # ä½ çš„åµŒå…¥åç§°
    }

    ```

    å®šä¹‰ LLM å¹¶ä½¿ç”¨ `LangchainLLMWrapper` åŒ…è£…ï¼Œä»¥ä¾¿åœ¨ ragas ä¸­ä½¿ç”¨ã€‚

    ```python
    from langchain_openai import AzureChatOpenAI
    from langchain_openai import AzureOpenAIEmbeddings
    from ragas.llms import LangchainLLMWrapper
    from ragas.embeddings import LangchainEmbeddingsWrapper
    generator_llm = LangchainLLMWrapper(AzureChatOpenAI(
        openai_api_version="2023-05-15",
        azure_endpoint=azure_configs["base_url"],
        azure_deployment=azure_configs["model_deployment"],
        model=azure_configs["model_name"],
        validate_base_url=False,
    ))

    # ä¸º answer_relevancyã€answer_correctness å’Œ answer_similarity åˆå§‹åŒ–åµŒå…¥
    generator_embeddings = LangchainEmbeddingsWrapper(AzureOpenAIEmbeddings(
        openai_api_version="2023-05-15",
        azure_endpoint=azure_configs["base_url"],
        azure_deployment=azure_configs["embedding_deployment"],
        model=azure_configs["embedding_name"],
    ))
    ```

    å¦‚éœ€äº†è§£æ›´å¤šå…³äºä½¿ç”¨å…¶ä»– Azure æœåŠ¡çš„ä¿¡æ¯ï¼Œè¯·å‚é˜… [langchain-azure](https://python.langchain.com/docs/integrations/chat/azure_chat_openai/) æ–‡æ¡£ã€‚

=== "å…¶ä»–"
    è‹¥ä½¿ç”¨å…¶ä»– LLM æä¾›å•†å¹¶é€šè¿‡ LangChain ä¸å…¶äº¤äº’ï¼Œå¯ä½¿ç”¨ `LangchainLLMWrapper` åŒ…è£…ä½ çš„ LLMï¼Œä»¥ä¾¿åœ¨ ragas ä¸­ä½¿ç”¨ã€‚

    ```python
    from ragas.llms import LangchainLLMWrapper
    generator_llm = LangchainLLMWrapper(your_llm_instance)
    ```

    æ›´è¯¦ç»†è¯´æ˜è¯·å‚é˜…[è‡ªå®šä¹‰æ¨¡å‹æŒ‡å—](../../howtos/customizations/customize_models.md)ã€‚

    è‹¥ä½¿ç”¨ LlamaIndexï¼Œå¯ä½¿ç”¨ `LlamaIndexLLMWrapper` åŒ…è£…ä½ çš„ LLMï¼Œä»¥ä¾¿åœ¨ ragas ä¸­ä½¿ç”¨ã€‚

    ```python
    from ragas.llms import LlamaIndexLLMWrapper
    generator_llm = LlamaIndexLLMWrapper(your_llm_instance)
    ```

    æœ‰å…³ LlamaIndex çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [LlamaIndex é›†æˆæŒ‡å—](./../../howtos/integrations/_llamaindex.md)ã€‚

    è‹¥ä»æ— æ³•åœ¨ Ragas ä¸­ä½¿ç”¨ä½ å–œæ¬¢çš„ LLM æä¾›å•†ï¼Œè¯·åœ¨æ­¤ [issue](https://github.com/vibrantlabsai/ragas/issues/1617) ä¸‹ç•™è¨€ï¼Œæˆ‘ä»¬ä¼šä¸ºå…¶æ·»åŠ æ”¯æŒ ğŸ™‚ã€‚
