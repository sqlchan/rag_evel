# è¯„ä¼°ç®€å• RAG ç³»ç»Ÿ

æœ¬æŒ‡å—æ—¨åœ¨è¯´æ˜ä½¿ç”¨ `ragas` æµ‹è¯•å’Œè¯„ä¼° RAG ç³»ç»Ÿçš„ç®€å•å·¥ä½œæµã€‚å‡å®šä½ å¯¹æ„å»º RAG ç³»ç»Ÿä¸è¯„ä¼°ä»…æœ‰åŸºç¡€äº†è§£ã€‚å®‰è£… `ragas` è¯·å‚è€ƒ [å®‰è£…è¯´æ˜](./install.md)ã€‚

## åŸºæœ¬é…ç½®

æˆ‘ä»¬å°†ä½¿ç”¨ `langchain_openai` é…ç½® LLM å’ŒåµŒå…¥æ¨¡å‹ä»¥æ„å»ºç®€å• RAGã€‚ä½ ä¹Ÿå¯ä»¥é€‰æ‹©å…¶ä»– LLM å’ŒåµŒå…¥æ¨¡å‹ï¼Œè¯¦è§ [åœ¨ LangChain ä¸­è‡ªå®šä¹‰æ¨¡å‹](https://python.langchain.com/docs/integrations/chat/)ã€‚


```python
from langchain_openai import ChatOpenAI
from ragas.embeddings import OpenAIEmbeddings
import openai

llm = ChatOpenAI(model="gpt-4o")
openai_client = openai.OpenAI()
embeddings = OpenAIEmbeddings(client=openai_client)
```

!!! note "OpenAI Embeddings API"
    `ragas.embeddings.OpenAIEmbeddings` æä¾› `embed_text`ï¼ˆå•æ¡ï¼‰å’Œ `embed_texts`ï¼ˆæ‰¹é‡ï¼‰ï¼Œè€Œä¸æ˜¯åƒéƒ¨åˆ† LangChain å°è£…é‚£æ ·çš„ `embed_query`/`embed_documents`ã€‚ä¸‹é¢ç¤ºä¾‹ä¸­å¯¹æ–‡æ¡£ä½¿ç”¨ `embed_texts`ï¼Œå¯¹æŸ¥è¯¢ä½¿ç”¨ `embed_text`ã€‚è¯¦è§ [OpenAI embeddings å®ç°](https://docs.ragas.io/en/stable/references/embeddings/\#ragas.embeddings.OpenAIEmbeddings)

### æ„å»ºç®€å• RAG ç³»ç»Ÿ

è¦æ„å»ºç®€å• RAG ç³»ç»Ÿï¼Œéœ€è¦å®šä¹‰ä»¥ä¸‹ç»„ä»¶ï¼š

- å®šä¹‰æ–‡æ¡£å‘é‡åŒ–æ–¹æ³•
- å®šä¹‰æ£€ç´¢ç›¸å…³æ–‡æ¡£çš„æ–¹æ³•
- å®šä¹‰ç”Ÿæˆå›ç­”çš„æ–¹æ³•

??? note "ç‚¹å‡»æŸ¥çœ‹ä»£ç "

    ```python

    import numpy as np

    class RAG:
        def __init__(self, model="gpt-4o"):
            import openai
            self.llm = ChatOpenAI(model=model)
            openai_client = openai.OpenAI()
            self.embeddings = OpenAIEmbeddings(client=openai_client)
            self.doc_embeddings = None
            self.docs = None

        def load_documents(self, documents):
            """åŠ è½½æ–‡æ¡£å¹¶è®¡ç®—å…¶åµŒå…¥ã€‚"""
            self.docs = documents
            self.doc_embeddings = self.embeddings.embed_texts(documents)

        def get_most_relevant_docs(self, query):
            """æ ¹æ®æŸ¥è¯¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚"""
            if not self.docs or not self.doc_embeddings:
                raise ValueError("Documents and their embeddings are not loaded.")
            
            query_embedding = self.embeddings.embed_text(query)
            similarities = [
                np.dot(query_embedding, doc_emb)
                / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))
                for doc_emb in self.doc_embeddings
            ]
            most_relevant_doc_index = np.argmax(similarities)
            return [self.docs[most_relevant_doc_index]]

        def generate_answer(self, query, relevant_doc):
            """æ ¹æ®æœ€ç›¸å…³æ–‡æ¡£ä¸ºç»™å®šæŸ¥è¯¢ç”Ÿæˆå›ç­”ã€‚"""
            prompt = f"question: {query}\n\nDocuments: {relevant_doc}"
            messages = [
                ("system", "You are a helpful assistant that answers questions based on given documents only."),
                ("human", prompt),
            ]
            ai_msg = self.llm.invoke(messages)
            return ai_msg.content
    ```

### åŠ è½½æ–‡æ¡£

ä¸‹é¢åŠ è½½ä¸€äº›æ–‡æ¡£å¹¶æµ‹è¯• RAG ç³»ç»Ÿã€‚

```python
sample_docs = [
    "Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.",
    "Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.",
    "Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.",
    "Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.",
    "Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine."
]
```

```python
# åˆå§‹åŒ– RAG å®ä¾‹
rag = RAG()

# åŠ è½½æ–‡æ¡£
rag.load_documents(sample_docs)

# æŸ¥è¯¢å¹¶æ£€ç´¢æœ€ç›¸å…³æ–‡æ¡£
query = "Who introduced the theory of relativity?"
relevant_doc = rag.get_most_relevant_docs(query)

# ç”Ÿæˆå›ç­”
answer = rag.generate_answer(query, relevant_doc)

print(f"Query: {query}")
print(f"Relevant Document: {relevant_doc}")
print(f"Answer: {answer}")
```


è¾“å‡ºï¼š
```
Query: Who introduced the theory of relativity?
Relevant Document: ['Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.']
Answer: Albert Einstein introduced the theory of relativity.
```

## æ”¶é›†è¯„ä¼°æ•°æ®

è¦æ”¶é›†è¯„ä¼°æ•°æ®ï¼Œé¦–å…ˆéœ€è¦ä¸€ç»„é’ˆå¯¹ RAG çš„æŸ¥è¯¢ã€‚æˆ‘ä»¬è®©è¿™äº›æŸ¥è¯¢ç»è¿‡ RAG ç³»ç»Ÿï¼Œå¹¶æ”¶é›†æ¯æ¡æŸ¥è¯¢çš„ `response`ã€`retrieved_contexts`ã€‚ä½ ä¹Ÿå¯ä»¥ optionally ä¸ºæ¯æ¡æŸ¥è¯¢å‡†å¤‡å‚è€ƒç­”æ¡ˆï¼Œç”¨äºè¯„ä¼°ç³»ç»Ÿè¡¨ç°ã€‚



```python


sample_queries = [
    "Who introduced the theory of relativity?",
    "Who was the first computer programmer?",
    "What did Isaac Newton contribute to science?",
    "Who won two Nobel Prizes for research on radioactivity?",
    "What is the theory of evolution by natural selection?"
]

expected_responses = [
    "Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.",
    "Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.",
    "Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.",
    "Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.",
    "Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'."
]
```

```python
dataset = []

for query,reference in zip(sample_queries,expected_responses):
    
    relevant_docs = rag.get_most_relevant_docs(query)
    response = rag.generate_answer(query, relevant_docs)
    dataset.append(
        {
            "user_input":query,
            "retrieved_contexts":relevant_docs,
            "response":response,
            "reference":reference
        }
    )
```

å°†æ•°æ®é›†åŠ è½½åˆ° `EvaluationDataset` å¯¹è±¡ä¸­ã€‚

```python
from ragas import EvaluationDataset
evaluation_dataset = EvaluationDataset.from_list(dataset)
```

## è¯„ä¼°

è¯„ä¼°æ•°æ®å·²å‡†å¤‡å¥½ã€‚ç°åœ¨å¯ä»¥ä½¿ç”¨ä¸€ç»„å¸¸ç”¨ RAG è¯„ä¼°æŒ‡æ ‡åœ¨æ”¶é›†åˆ°çš„æ•°æ®é›†ä¸Šè¯„ä¼° RAG ç³»ç»Ÿã€‚è¯„ä¼°æ—¶å¯é€‰ç”¨ä»»æ„æ¨¡å‹ä½œä¸º [è¯„ä¼°ç”¨ LLM](./../howtos/customizations/customize_models.md)ã€‚

```python
from ragas import evaluate
from ragas.llms import LangchainLLMWrapper


evaluator_llm = LangchainLLMWrapper(llm)
from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness

result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)
result
```

è¾“å‡º
```
{'context_recall': 1.0000, 'faithfulness': 0.8571, 'factual_correctness': 0.7280}
```

### éœ€è¦å€ŸåŠ©è¯„ä¼°æ”¹è¿›ä½ çš„ AI åº”ç”¨ï¼Ÿ

è¿‡å»ä¸¤å¹´é‡Œï¼Œæˆ‘ä»¬é€šè¿‡è¯„ä¼°å¸®åŠ©äº†è®¸å¤š AI åº”ç”¨æ”¹è¿›ã€‚

æˆ‘ä»¬æ­£åœ¨æŠŠè¿™äº›ç»éªŒæ²‰æ·€æˆäº§å“ï¼Œç”¨è¯„ä¼°å¾ªç¯æ›¿ä»£â€œæ„Ÿè§‰å¥½ä¸å¥½â€çš„æ£€æŸ¥ï¼Œè®©ä½ æ›´ä¸“æ³¨äºæŠŠ AI åº”ç”¨åšå¥½ã€‚

è‹¥ä½ å¸Œæœ›å€ŸåŠ©è¯„ä¼°æ”¹è¿›å’Œæ‰©å±• AI åº”ç”¨ï¼š

ğŸ”— é¢„çº¦ [æ—¶æ®µ](https://bit.ly/3EBYq4J) æˆ–å‘é‚®ä»¶ï¼š[founders@vibrantlabs.com](mailto:founders@vibrantlabs.com)ã€‚

![](../_static/ragas_app.gif)


## ä¸‹ä¸€æ­¥

- [ä¸º RAG è¯„ä¼°ç”Ÿæˆæµ‹è¯•æ•°æ®](rag_testset_generation.md)
