# å¦‚ä½•ä¼°ç®—è¯„ä¼°ä¸æµ‹è¯•é›†ç”Ÿæˆçš„æˆæœ¬ä¸ç”¨é‡

åœ¨ä½¿ç”¨ LLM è¿›è¡Œè¯„ä¼°å’Œæµ‹è¯•é›†ç”Ÿæˆæ—¶ï¼Œæˆæœ¬æ˜¯é‡è¦å› ç´ ã€‚Ragas æä¾›äº†ä¸€äº›å·¥å…·æ¥å¸®åŠ©ä½ ä¼°ç®—ã€‚

## å®ç° `TokenUsageParser`

é»˜è®¤æƒ…å†µä¸‹ï¼ŒRagas ä¸ä¼šä¸º `evaluate()` è®¡ç®— token ç”¨é‡ã€‚è¿™æ˜¯å› ä¸º LangChain çš„ LLM å¹¶ä¸æ€»æ˜¯ä»¥ç»Ÿä¸€æ–¹å¼è¿”å› token ç”¨é‡ä¿¡æ¯ã€‚å› æ­¤è¦è·å¾—ç”¨é‡æ•°æ®ï¼Œéœ€è¦å®ç° `TokenUsageParser`ã€‚

`TokenUsageParser` æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè§£æ LangChain æ¨¡å‹ `generate_prompt()` è¿”å›çš„ `LLMResult` æˆ– `ChatResult`ï¼Œå¹¶è¾“å‡º Ragas æœŸæœ›çš„ `TokenUsage`ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨æˆ‘ä»¬å·²å®šä¹‰è§£æå™¨è§£æ OpenAI çš„ç¤ºä¾‹ã€‚


```python
from langchain_openai.chat_models import ChatOpenAI
from langchain_core.prompt_values import StringPromptValue

gpt4o = ChatOpenAI(model="gpt-4o")
p = StringPromptValue(text="hai there")
llm_result = gpt4o.generate_prompt([p])

# lets import a parser for OpenAI
from ragas.cost import get_token_usage_for_openai

get_token_usage_for_openai(llm_result)
```
Output
```
TokenUsage(input_tokens=9, output_tokens=9, model='')
```


ä½ å¯ä»¥è‡ªå®šä¹‰è§£æå™¨ï¼Œæˆ–ä½¿ç”¨å·²å®šä¹‰çš„è§£æå™¨ã€‚è‹¥å¸Œæœ›ä¸ºæŸ LLM å‚å•†å»ºè®®æˆ–è´¡çŒ®è§£æå™¨ï¼Œè¯·æŸ¥çœ‹æ­¤ [issue](https://github.com/vibrantlabsai/ragas/issues/1151) ğŸ™‚ã€‚

## è¯„ä¼°çš„ Token ç”¨é‡

ä½¿ç”¨ `get_token_usage_for_openai` è§£æå™¨è®¡ç®—æŸæ¬¡è¯„ä¼°çš„ token ç”¨é‡ã€‚


```python
from ragas import EvaluationDataset
from datasets import load_dataset

dataset = load_dataset("vibrantlabsai/amnesty_qa", "english_v3")

eval_dataset = EvaluationDataset.from_hf_dataset(dataset["eval"])
```
Output
```
Repo card metadata block was not found. Setting CardData to empty.
```

å°†è§£æå™¨ä¼ å…¥ `evaluate()` åï¼Œæˆæœ¬ä¼šè¢«è®¡ç®—å¹¶åŒ…å«åœ¨è¿”å›çš„ `Result` å¯¹è±¡ä¸­ã€‚


```python
from ragas import evaluate
from ragas.metrics import LLMContextRecall

from ragas.cost import get_token_usage_for_openai

result = evaluate(
    eval_dataset,
    metrics=[LLMContextRecall()],
    llm=gpt4o,
    token_usage_parser=get_token_usage_for_openai,
)
```
Output
```
Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]
```


```python
result.total_tokens()
```
Output
```
TokenUsage(input_tokens=25097, output_tokens=3757, model='')
```


å¯é€šè¿‡å‘ `Result.total_cost()` ä¼ å…¥æ¯ token æˆæœ¬æ¥è®¡ç®—æ¯æ¬¡è¿è¡Œçš„æˆæœ¬ã€‚

æœ¬ä¾‹ä¸­ GPT-4o ä¸ºæ¯ç™¾ä¸‡è¾“å…¥ token 5 ç¾å…ƒã€æ¯ç™¾ä¸‡è¾“å‡º token 15 ç¾å…ƒã€‚


```python
result.total_cost(cost_per_input_token=5 / 1e6, cost_per_output_token=15 / 1e6)
```

Output
```
1.1692900000000002
```


## æµ‹è¯•é›†ç”Ÿæˆçš„ Token ç”¨é‡

æµ‹è¯•é›†ç”Ÿæˆå¯ä½¿ç”¨åŒä¸€è§£æå™¨ï¼Œä½†éœ€å°† `token_usage_parser` ä¼ å…¥ `generate()`ã€‚ç›®å‰ä»…è®¡ç®—ç”Ÿæˆè¿‡ç¨‹çš„æˆæœ¬ï¼Œä¸åŒ…å« transforms çš„æˆæœ¬ã€‚

ä¸‹é¢ç¤ºä¾‹åŠ è½½å·²æœ‰ KnowledgeGraph å¹¶ç”Ÿæˆæµ‹è¯•é›†ã€‚è‹¥æƒ³äº†è§£å¦‚ä½•ç”Ÿæˆæµ‹è¯•é›†ï¼Œè¯·å‚é˜… [æµ‹è¯•é›†ç”Ÿæˆ](../../getstarted/rag_testset_generation_zh.md#a-deeper-look)ã€‚


```python
from ragas.testset.graph import KnowledgeGraph

# loading an existing KnowledgeGraph
# make sure to change the path to the location of the KnowledgeGraph file
kg = KnowledgeGraph.load("../../../experiments/scratchpad_kg.json")
kg
```

Output
```
KnowledgeGraph(nodes: 47, relationships: 109)



### Choose your LLM

--8<--
choose_generator_llm.md
--8<--


```python
from ragas.testset import TestsetGenerator
from ragas.llms import llm_factory

tg = TestsetGenerator(llm=llm_factory(), knowledge_graph=kg)
# generating a testset
testset = tg.generate(testset_size=10, token_usage_parser=get_token_usage_for_openai)
```


```python
# total cost for the generation process
testset.total_cost(cost_per_input_token=5 / 1e6, cost_per_output_token=15 / 1e6)
```

Output
```
0.20967000000000002
```
