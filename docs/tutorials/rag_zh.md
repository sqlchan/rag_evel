# è¯„ä¼°ç®€å• RAG ç³»ç»Ÿ

æœ¬æ•™ç¨‹å°†ç¼–å†™ä¸€ä¸ªç®€å•çš„è¯„ä¼°æµæ°´çº¿ï¼Œç”¨äºè¯„ä¼° RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿã€‚å­¦å®Œæœ¬æ•™ç¨‹åï¼Œä½ å°†æŒæ¡å¦‚ä½•é€šè¿‡è¯„ä¼°é©±åŠ¨å¼€å‘æ¥è¯„ä¼°å¹¶è¿­ä»£ RAG ç³»ç»Ÿã€‚

```mermaid
flowchart LR
    A["Query<br/>'What is Ragas 0.3?'"] --> B[Retrieval System]
    
    C[Document Corpus<br/> Ragas 0.3 DocsğŸ“„] --> B
    
    B --> D[LLM + Prompt]
    A --> D
    
    D --> E[Final Answer]
```

æˆ‘ä»¬å°†ä»ä¸€ä¸ªç®€å• RAG ç³»ç»Ÿå¼€å§‹ï¼šä»æ–‡æ¡£åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆã€‚

```bash
python -m ragas_examples.rag_eval.rag
```


æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸º RAG ç³»ç»Ÿå†™ä¸‹è‹¥å¹²ç¤ºä¾‹æŸ¥è¯¢å’ŒæœŸæœ›è¾“å‡ºï¼Œå¹¶è½¬æ¢ä¸º CSV æ–‡ä»¶ã€‚

```python
import pandas as pd

samples = [
    {"query": "What is Ragas 0.3?", "grading_notes": "- Ragas 0.3 is a library for evaluating LLM applications."},
    {"query": "How to install Ragas?", "grading_notes": "- install from source  - install from pip using ragas[examples]"},
    {"query": "What are the main features of Ragas?", "grading_notes": "organised around - experiments - datasets - metrics."}
]
pd.DataFrame(samples).to_csv("datasets/test_dataset.csv", index=False)
```

ä¸ºäº†è¯„ä¼° RAG ç³»ç»Ÿçš„æ€§èƒ½ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåŸºäº LLM çš„æŒ‡æ ‡ï¼šå°† RAG ç³»ç»Ÿè¾“å‡ºä¸è¯„åˆ†è¯´æ˜è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶æ®æ­¤è¾“å‡ºé€šè¿‡/ä¸é€šè¿‡ã€‚

```python
from ragas.metrics import DiscreteMetric
my_metric = DiscreteMetric(
    name="correctness",
    prompt = "Check if the response contains points mentioned from the grading notes and return 'pass' or 'fail'.\nResponse: {response} Grading Notes: {grading_notes}",
    allowed_values=["pass", "fail"],
)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç¼–å†™å®éªŒå¾ªç¯ï¼šåœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿è¡Œ RAG ç³»ç»Ÿï¼Œä½¿ç”¨è¯¥æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ° CSV æ–‡ä»¶ã€‚

```python
@experiment()
async def run_experiment(row):
    response = rag_client.query(row["query"])
    
    score = my_metric.score(
        llm=llm,
        response=response.get("answer", " "),
        grading_notes=row["grading_notes"]
    )

    experiment_view = {
        **row,
        "response": response.get("answer", ""),
        "score": score.value,
        "log_file": response.get("logs", " "),
    }
    return experiment_view
```

æ­¤åï¼Œæ¯æ¬¡ä¿®æ”¹ RAG æµæ°´çº¿æ—¶ï¼Œéƒ½å¯ä»¥è¿è¡Œå®éªŒï¼ŒæŸ¥çœ‹å¯¹ RAG æ€§èƒ½çš„å½±å“ã€‚

## ç«¯åˆ°ç«¯è¿è¡Œç¤ºä¾‹

1. é…ç½®ä½ çš„ OpenAI API å¯†é’¥
```bash
export OPENAI_API_KEY="your_openai_api_key"
```
2. è¿è¡Œè¯„ä¼°
```bash
python -m ragas_examples.rag_eval.evals
```

å®Œæˆï¼ä½ å·²ç»æˆåŠŸä½¿ç”¨ Ragas å®Œæˆäº†ç¬¬ä¸€æ¬¡è¯„ä¼°ã€‚ç°åœ¨å¯ä»¥æ‰“å¼€ `experiments/experiment_name.csv` æ–‡ä»¶æŸ¥çœ‹ç»“æœã€‚
